{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Network (DQN) with Hindsight Experience Replay\n",
    "---\n",
    "\n",
    "#### Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, random\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "FUTURE_K = 4            # hindsight experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define DQN Agent and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# her 1            \n",
    "if HER:\n",
    "    for k in range(num_HER):\n",
    "        # sample an experience from G, and set its final state as new target g'\n",
    "        _, _, _, target_new, _ = episode_experience[np.random.randint(t, num_experience)]\n",
    "        # Compute s_t||g', s_t+1||g'\n",
    "        obs_new = np.concatenate([state_t, target_new], axis = -1)\n",
    "        obs_next_new = np.concatenate([state_next_t, target_new], axis = -1)\n",
    "        # Compute r'\n",
    "        if np.sum(np.array(state_next_t) == np.array(target_new)) == obs_size:\n",
    "            reward_new = 0\n",
    "        else:\n",
    "            reward_new = -1\n",
    "        transition_new = np.reshape(np.array([obs_new, action_t, reward_new, obs_next_new]),[1,4])\n",
    "        MP.put(transition_new)\n",
    "                    \n",
    "# her 2\n",
    "\n",
    "if hindsight:\n",
    "    for _ in range(future_k):\n",
    "        future = random.randint(t, steps_taken)  # index of future time step\n",
    "        new_goal = episode_trajectory[future].next_state  # take future next_state and set as goal\n",
    "        new_reward, new_done = env.compute_reward(next_state, new_goal)\n",
    "        state_, next_state_ = torch.cat((state, new_goal)), torch.cat((next_state, new_goal))\n",
    "        self.memory.add(state_, action, new_reward, next_state_, new_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()                      # this change the local net to eval mode\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()                     # this just return the local net back to train mode\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        target_q_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)    \n",
    "        \"\"\"\n",
    "        # disregard action, get best value! \n",
    "        # why so many next states? answer: the qnetwork will return each corresponding next states action, the max will pick from each the           best action\n",
    "        \n",
    "        # explanation on detach (https://discuss.pytorch.org/t/detach-no-grad-and-requires-grad/16915/7)\n",
    "        \"\"\"\n",
    "        # Compute Q targets for current states \n",
    "        target_q = rewards+(gamma*target_q_next*(1-dones))\n",
    "                            \n",
    "        # Get expected Q values from local model\n",
    "        expected_q = self.qnetwork_local(states).gather(1, actions)\n",
    "        \"\"\"\n",
    "        this uses gather instead of detach like target since it only give a s*** to action taken\n",
    "        # explanation on gather (https://stackoverflow.com/questions/50999977/what-does-the-gather-function-do-in-pytorch-in-layman-terms)\n",
    "        \"\"\"\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(expected_q, target_q)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "                            \n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)\n",
    "\n",
    "agent = Agent(state_size=8, action_size=4, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the Environment and Agent\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  You are welcome to amend the supplied values of the parameters in the function, to try to see if you can get better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Episode_experience():\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "        \n",
    "    def add(self, state, action, reward, next_state, done, goal):\n",
    "        self.memory += [(state, action, reward, next_state, done, goal)]\n",
    "        \n",
    "    def clear(self):\n",
    "        self.memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array_equal([255,255,255],[255,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            if hindsight:\n",
    "                ep_experience.add(state, action, reward, next_state, done, goal)\n",
    "\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "                \n",
    "        if hindsight: \n",
    "            # The strategy can be changed here\n",
    "            # goal = state # HER, with substituted goal=final_state\n",
    "            for t in range(len(ep_experience.memory)):\n",
    "                for k in range(K):\n",
    "                    future = np.random.randint(t, len(ep_experience.memory))\n",
    "                    goal = ep_experience.memory[future][3] # next_state of future\n",
    "                    state,action,reward,next_state,_,_ = ep_experience.memory[t]\n",
    "                    done = np.array_equal(next_state, goal)\n",
    "                    agent.step(state, action, reward, next_state, done)\n",
    "                    ep_experience_her.add(state, action, reward, next_state, done)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -191.75\n",
      "Episode 200\tAverage Score: -138.21\n",
      "Episode 300\tAverage Score: -39.610\n",
      "Episode 400\tAverage Score: -23.80\n",
      "Episode 500\tAverage Score: 6.5650\n",
      "Episode 600\tAverage Score: 24.90\n",
      "Episode 700\tAverage Score: 123.95\n",
      "Episode 800\tAverage Score: 186.46\n",
      "Episode 853\tAverage Score: 200.82\n",
      "Environment solved in 753 episodes!\tAverage Score: 200.82\n"
     ]
    }
   ],
   "source": [
    "# train the agent\n",
    "scores = dqn(n_episodes=2000, max_t=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchDisplayException",
     "evalue": "Cannot connect to \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cdb5c13011f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIEWPORT_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIEWPORT_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     raise ImportError('''\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36mget_default_display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[0;32m-> 1845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/pytorch/lib/python3.6/site-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "for i in range(5):\n",
    "    state = env.reset()\n",
    "    for j in range(200):\n",
    "        action = agent.act(state)\n",
    "        env.render()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
